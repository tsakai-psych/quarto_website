{
  "hash": "931779ae031529e57a577718e59e287e",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"purrr::mapを使ってpsych::alphaを一気に処理する\"\ndate: 2025-10-25\nabstract: |\n  `purrr::map()`の中で`psych::alpha()`を使って、元のdfから一気にα係数の処理をしてみた。\ncategories: [R memo, preprocess, analysis]\nformat: html\nknitr:\n  opts_knit: \n    R.options:\n      width: 120\neditor_options: \n  chunk_output_type: console\n---\n\n# Packages\n\n::: {.cell}\n\n```{.r .cell-code}\npacman::p_load(\n  tidyverse,\n  psych\n)\n```\n:::\n\n\n# Content\nデモデータとして`psych::bfi`を使います。\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(bfi, package = \"psych\")\n```\n:::\n\nロードされるデータのうち、`bfi`は2800行28列のデータで、列の最初の25項目は5因子に分かれるパーソナリティに関する項目が各5つずつ、残りの3列は性別、学歴、年齢が含まれています。\n\n::: {.cell}\n\n```{.r .cell-code}\nstr(bfi)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n'data.frame':\t2800 obs. of  28 variables:\n $ A1       : int  2 2 5 4 2 6 2 4 4 2 ...\n $ A2       : int  4 4 4 4 3 6 5 3 3 5 ...\n $ A3       : int  3 5 5 6 3 5 5 1 6 6 ...\n $ A4       : int  4 2 4 5 4 6 3 5 3 6 ...\n $ A5       : int  4 5 4 5 5 5 5 1 3 5 ...\n $ C1       : int  2 5 4 4 4 6 5 3 6 6 ...\n $ C2       : int  3 4 5 4 4 6 4 2 6 5 ...\n $ C3       : int  3 4 4 3 5 6 4 4 3 6 ...\n $ C4       : int  4 3 2 5 3 1 2 2 4 2 ...\n $ C5       : int  4 4 5 5 2 3 3 4 5 1 ...\n $ E1       : int  3 1 2 5 2 2 4 3 5 2 ...\n $ E2       : int  3 1 4 3 2 1 3 6 3 2 ...\n $ E3       : int  3 6 4 4 5 6 4 4 NA 4 ...\n $ E4       : int  4 4 4 4 4 5 5 2 4 5 ...\n $ E5       : int  4 3 5 4 5 6 5 1 3 5 ...\n $ N1       : int  3 3 4 2 2 3 1 6 5 5 ...\n $ N2       : int  4 3 5 5 3 5 2 3 5 5 ...\n $ N3       : int  2 3 4 2 4 2 2 2 2 5 ...\n $ N4       : int  2 5 2 4 4 2 1 6 3 2 ...\n $ N5       : int  3 5 3 1 3 3 1 4 3 4 ...\n $ O1       : int  3 4 4 3 3 4 5 3 6 5 ...\n $ O2       : int  6 2 2 3 3 3 2 2 6 1 ...\n $ O3       : int  3 4 5 4 4 5 5 4 6 5 ...\n $ O4       : int  4 3 5 3 3 6 6 5 6 5 ...\n $ O5       : int  3 3 2 5 3 1 1 3 1 2 ...\n $ gender   : int  1 2 2 2 1 2 1 1 1 2 ...\n $ education: int  NA NA NA NA NA 3 NA 2 1 NA ...\n $ age      : int  16 18 17 17 17 21 18 19 19 17 ...\n```\n\n\n:::\n:::\n\n`bfi.keys`の方は、25項目のパーソナリティに関する項目がそれぞれのど下位尺度を構成するのかという情報がlist形式で収められています。頭に-がついているのは、逆転項目のしるしです。\n\n::: {.cell}\n\n```{.r .cell-code}\nbfi.keys\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$agree\n[1] \"-A1\" \"A2\"  \"A3\"  \"A4\"  \"A5\" \n\n$conscientious\n[1] \"C1\"  \"C2\"  \"C3\"  \"-C4\" \"-C5\"\n\n$extraversion\n[1] \"-E1\" \"-E2\" \"E3\"  \"E4\"  \"E5\" \n\n$neuroticism\n[1] \"N1\" \"N2\" \"N3\" \"N4\" \"N5\"\n\n$openness\n[1] \"O1\"  \"-O2\" \"O3\"  \"O4\"  \"-O5\"\n```\n\n\n:::\n:::\n\n\nこのデータのそれぞれの下位尺度ごとにα係数を求めたいとなった場合、ふつうはこんな感じになると思います。\n\n::: {.cell}\n\n```{.r .cell-code}\nres_alpha_a <- bfi |>\n  select(A1:A5) |>\n  psych::alpha(\n    keys = \"A1\"\n  )\n\nres_alpha_a\n\nres_alpha_c <- bfi |>\n  select(C1:C5) |>\n  psych::alpha(\n    keys = c(\"C4\", \"C5\")\n  )\n\nres_alpha_c\n```\n:::\n\n列名選択と逆転項目の指定を自分で頑張る方法です。これを5因子分繰り返します。可読性は悪くないので、これでも十分な気がします。\n\nただ、せっかくなのでほとんどをRに任せて１回の処理でできたら、それもそれでいい気がします。ということで試してみました。\n\n## やりやすいデータの場合\nまず、処理しやすいようにデータをlong型にします。ついでに`tibble::rownames_to_column()`でrownameをid列に変えておきます。id列がないと`tidyr::pivot_wider()`出来なくなるので、少なくともその処理の前にはやっておきます。\n\n::: {.cell}\n\n```{.r .cell-code}\nbfi |>\n  rownames_to_column(var = \"id\") |>\n  pivot_longer(\n    cols = matches(\"\\\\w\\\\d\"), # <1>\n    names_to = \"items\"\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 70,000 × 6\n   id    gender education   age items value\n   <chr>  <int>     <int> <int> <chr> <int>\n 1 61617      1        NA    16 A1        2\n 2 61617      1        NA    16 A2        4\n 3 61617      1        NA    16 A3        3\n 4 61617      1        NA    16 A4        4\n 5 61617      1        NA    16 A5        4\n 6 61617      1        NA    16 C1        2\n 7 61617      1        NA    16 C2        3\n 8 61617      1        NA    16 C3        3\n 9 61617      1        NA    16 C4        4\n10 61617      1        NA    16 C5        4\n# ℹ 69,990 more rows\n```\n\n\n:::\n:::\n\n1. 引数`cols`はtidy-selectの文法なので`-c(id, gender, education, age)`でもいいです。longにしたい列名が「文字1文字数字1文字」なのがわかっているので、`dplyr::matches()`で正規表現を使って絞りました。\n\n次に、nest用の列を作ってnestします。今回は列名に下位尺度が入っているので、それを抽出すれば簡単にnest用の列が完成です。やりやすいデータとはこのことを言っています。\n\n::: {.cell}\n\n```{.r .cell-code}\nbfi |>\n  rownames_to_column(var = \"id\") |>\n  pivot_longer(\n    cols = matches(\"\\\\w\\\\d\"),\n    names_to = \"items\"\n  ) |>\n  mutate(\n    nest_key = str_extract(items, \"^.\") |> # <1>\n      tolower() # <2>\n  ) |>\n  nest(.by = nest_key) # <3>\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 × 2\n  nest_key data                 \n  <chr>    <list>               \n1 a        <tibble [14,000 × 6]>\n2 c        <tibble [14,000 × 6]>\n3 e        <tibble [14,000 × 6]>\n4 n        <tibble [14,000 × 6]>\n5 o        <tibble [14,000 × 6]>\n```\n\n\n:::\n:::\n\n1. items（列名のベクトル）の各要素から最初の一文字だけ抜ければいいので、`stringr::str_extract()`でいいです。\n2. あとで`bfi.keys`から抽出しやすくすために、小文字にします。\n3. nestに使った列以外の残りは、引数`.keys`を指定しなければdata列にまとまります。\n\nnestされたデータを処理します。data列はlistなので、中の各要素を処理したいときは`purrr::map()`が使えます。data列の各要素はデータフレームで、しかもaの行はAで始まる項目だけ、cの行はCで始まる項目だけ、eの行は…のlongデータになっています。そのため、`map()`の中でwide型に直して必要列以外取り除き、`psych::alpha()`に入れてあげればいいわけです。\n\n::: {.cell}\n\n```{.r .cell-code}\nbfi |>\n  rownames_to_column(var = \"id\") |>\n  pivot_longer(\n    cols = matches(\"\\\\w\\\\d\"),\n    names_to = \"items\"\n  ) |>\n  mutate(\n    nest_key = str_extract(items, \"^.\") |>\n      tolower()\n  ) |>\n  nest(.by = nest_key) |>\n  mutate(\n    bfi_key_name = str_subset( # <1>\n      names(bfi.keys), # <1>\n      pattern = paste0(\"^\", nest_key) # <1>\n    ), # <1>\n    res_alpha = map(\n      .x = data,\n      .f = \\(x) {\n         x |>\n          pivot_wider(\n            names_from = items,\n            values_from = value\n          ) |>\n          select(matches(\"\\\\w\\\\d\")) |>\n          psych::alpha(\n            keys = bfi.keys[[bfi_key_name]] |> # <2>\n              str_subset(pattern = \"^-\") |> # <3>\n              str_remove(pattern = \"^-\") # <3>\n          )\n      }\n    ) |>\n      set_names(bfi_key_name), # <4>\n    .by = nest_key # <5>\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 × 4\n  nest_key data                  bfi_key_name  res_alpha   \n  <chr>    <list>                <chr>         <named list>\n1 a        <tibble [14,000 × 6]> agree         <psych>     \n2 c        <tibble [14,000 × 6]> conscientious <psych>     \n3 e        <tibble [14,000 × 6]> extraversion  <psych>     \n4 n        <tibble [14,000 × 6]> neuroticism   <psych>     \n5 o        <tibble [14,000 × 6]> openness      <psych>     \n```\n\n\n:::\n:::\n\n1. `alpha()`の中で`bfi.keys`の要素名を使えるようにしたいので、ここで抜き出しておきます。\n2. まさに上の処理で抜き出した要素名をここで使います。\n3. 引数`keys`は、逆転する項目の項目名を文字列ベクトルで入れるか、逆転する項目は-1、そのままの項目は1にした数値ベクトルを入れます。今回は前者で入れるので、`bfi.keys`の各要素（文字列ベクトル）のうち、`stringr::str_subset()`を使って-で始まる項目だけを抽出して、`str_remove()`で-を取り除きます。\n4. `map()`の戻り値のlistに名前を付けたいので`map() |> purrr::set_names()`とします。nestデータのほかの列の要素を使えるので、`dplyr::group_map() |> set_names()`よりもいい気がします。\n5. 引数`.by`にnest_key列を指定して、実質rowwise処理をします。これを指定することで、(2)の処理で`[[bfi_key_name]]`のところにbfi_key_name列の要素が1つだけ入ります。これがないと、(2)の処理で要素5の文字列ベクトル`c（\"agree\", \"conscientious\", ...）`が`[[`の中に入ってしまうのでエラーになります。\n\n最後に結果が詰まったres_alpha列だけ取り出します。データフレームからある1列の要素を取り出すときは`dplyr::pull()`が使えます。res_alpha列は`map()`を使って作ったので、各下位尺度のα係数が入ったlistが返ってきます。\n\n::: {.cell}\n\n```{.r .cell-code}\nbfi |>\n  rownames_to_column(var = \"id\") |>\n  pivot_longer(\n    cols = matches(\"\\\\w\\\\d\"),\n    names_to = \"items\"\n  ) |>\n  mutate(\n    nest_key = str_extract(items, \"^.\") |>\n      tolower()\n  ) |>\n  nest(.by = nest_key) |>\n  mutate(\n    bfi_key_name = str_subset(\n      names(bfi.keys),\n      pattern = paste0(\"^\", nest_key)\n    ),\n    res_alpha = map(\n      .x = data,\n      .f = \\(x) {\n         x |>\n          pivot_wider(\n            names_from = items,\n            values_from = value\n          ) |>\n          select(matches(\"\\\\w\\\\d\")) |>\n          psych::alpha(\n            keys = bfi.keys[[bfi_key_name]] |> \n              str_subset(pattern = \"^-\") |> \n              str_remove(pattern = \"^-\")\n          )\n      }\n    ) |>\n      set_names(bfi_key_name),\n    .by = nest_key\n  ) |>\n  pull(res_alpha) # <1>\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$agree\n\nReliability analysis   \nCall: psych::alpha(x = select(pivot_wider(x, names_from = items, values_from = value), \n    matches(\"\\\\w\\\\d\")), keys = str_remove(str_subset(bfi.keys[[bfi_key_name]], \n    pattern = \"^-\"), pattern = \"^-\"))\n\n  raw_alpha std.alpha G6(smc) average_r S/N   ase mean  sd median_r\n       0.7      0.71    0.68      0.33 2.5 0.009  4.7 0.9     0.34\n\n    95% confidence boundaries \n         lower alpha upper\nFeldt     0.69   0.7  0.72\nDuhachek  0.69   0.7  0.72\n\n Reliability if an item is dropped:\n    raw_alpha std.alpha G6(smc) average_r S/N alpha se  var.r med.r\nA1-      0.72      0.72    0.67      0.40 2.6   0.0087 0.0065  0.38\nA2       0.62      0.63    0.58      0.29 1.7   0.0119 0.0168  0.29\nA3       0.60      0.61    0.56      0.28 1.6   0.0124 0.0094  0.32\nA4       0.69      0.69    0.65      0.36 2.3   0.0098 0.0157  0.37\nA5       0.64      0.66    0.60      0.32 1.9   0.0111 0.0125  0.34\n\n Item statistics \n       n raw.r std.r r.cor r.drop mean  sd\nA1- 2784  0.58  0.57  0.38   0.31  4.6 1.4\nA2  2773  0.73  0.75  0.67   0.56  4.8 1.2\nA3  2774  0.76  0.77  0.71   0.59  4.6 1.3\nA4  2781  0.65  0.63  0.47   0.39  4.7 1.5\nA5  2784  0.69  0.70  0.59   0.49  4.6 1.3\n\nNon missing response frequency for each item\n      1    2    3    4    5    6 miss\nA1 0.33 0.29 0.14 0.12 0.08 0.03 0.01\nA2 0.02 0.05 0.05 0.20 0.37 0.31 0.01\nA3 0.03 0.06 0.07 0.20 0.36 0.27 0.01\nA4 0.05 0.08 0.07 0.16 0.24 0.41 0.01\nA5 0.02 0.07 0.09 0.22 0.35 0.25 0.01\n\n$conscientious\n\nReliability analysis   \nCall: psych::alpha(x = select(pivot_wider(x, names_from = items, values_from = value), \n    matches(\"\\\\w\\\\d\")), keys = str_remove(str_subset(bfi.keys[[bfi_key_name]], \n    pattern = \"^-\"), pattern = \"^-\"))\n\n  raw_alpha std.alpha G6(smc) average_r S/N    ase mean   sd median_r\n      0.73      0.73    0.69      0.35 2.7 0.0081  4.3 0.95     0.34\n\n    95% confidence boundaries \n         lower alpha upper\nFeldt     0.71  0.73  0.74\nDuhachek  0.71  0.73  0.74\n\n Reliability if an item is dropped:\n    raw_alpha std.alpha G6(smc) average_r S/N alpha se  var.r med.r\nC1       0.69      0.70    0.64      0.36 2.3   0.0093 0.0037  0.35\nC2       0.67      0.68    0.62      0.34 2.1   0.0099 0.0056  0.34\nC3       0.69      0.69    0.64      0.36 2.3   0.0096 0.0070  0.36\nC4-      0.65      0.66    0.60      0.33 2.0   0.0107 0.0037  0.32\nC5-      0.69      0.69    0.63      0.36 2.2   0.0096 0.0017  0.35\n\n Item statistics \n       n raw.r std.r r.cor r.drop mean  sd\nC1  2779  0.65  0.67  0.54   0.45  4.5 1.2\nC2  2776  0.70  0.71  0.60   0.50  4.4 1.3\nC3  2780  0.66  0.67  0.54   0.46  4.3 1.3\nC4- 2774  0.74  0.73  0.64   0.55  4.4 1.4\nC5- 2784  0.72  0.68  0.57   0.48  3.7 1.6\n\nNon missing response frequency for each item\n      1    2    3    4    5    6 miss\nC1 0.03 0.06 0.10 0.24 0.37 0.21 0.01\nC2 0.03 0.09 0.11 0.23 0.35 0.20 0.01\nC3 0.03 0.09 0.11 0.27 0.34 0.17 0.01\nC4 0.28 0.29 0.17 0.16 0.08 0.02 0.01\nC5 0.18 0.20 0.12 0.22 0.17 0.10 0.01\n\n$extraversion\n\nReliability analysis   \nCall: psych::alpha(x = select(pivot_wider(x, names_from = items, values_from = value), \n    matches(\"\\\\w\\\\d\")), keys = str_remove(str_subset(bfi.keys[[bfi_key_name]], \n    pattern = \"^-\"), pattern = \"^-\"))\n\n  raw_alpha std.alpha G6(smc) average_r S/N   ase mean  sd median_r\n      0.76      0.76    0.73      0.39 3.2 0.007  4.1 1.1     0.38\n\n    95% confidence boundaries \n         lower alpha upper\nFeldt     0.75  0.76  0.78\nDuhachek  0.75  0.76  0.78\n\n Reliability if an item is dropped:\n    raw_alpha std.alpha G6(smc) average_r S/N alpha se  var.r med.r\nE1-      0.73      0.73    0.67      0.40 2.6   0.0084 0.0044  0.38\nE2-      0.69      0.69    0.63      0.36 2.3   0.0095 0.0028  0.35\nE3       0.73      0.73    0.67      0.40 2.7   0.0082 0.0071  0.40\nE4       0.70      0.70    0.65      0.37 2.4   0.0091 0.0033  0.38\nE5       0.74      0.74    0.69      0.42 2.9   0.0078 0.0043  0.42\n\n Item statistics \n       n raw.r std.r r.cor r.drop mean  sd\nE1- 2777  0.72  0.70  0.59   0.52  4.0 1.6\nE2- 2784  0.78  0.76  0.69   0.61  3.9 1.6\nE3  2775  0.68  0.70  0.58   0.50  4.0 1.4\nE4  2791  0.75  0.75  0.66   0.58  4.4 1.5\nE5  2779  0.64  0.66  0.52   0.45  4.4 1.3\n\nNon missing response frequency for each item\n      1    2    3    4    5    6 miss\nE1 0.24 0.23 0.15 0.16 0.13 0.09 0.01\nE2 0.19 0.24 0.12 0.22 0.14 0.09 0.01\nE3 0.05 0.11 0.15 0.30 0.27 0.13 0.01\nE4 0.05 0.09 0.10 0.16 0.34 0.26 0.00\nE5 0.03 0.08 0.10 0.22 0.34 0.22 0.01\n\n$neuroticism\n\nReliability analysis   \nCall: psych::alpha(x = select(pivot_wider(x, names_from = items, values_from = value), \n    matches(\"\\\\w\\\\d\")), keys = str_remove(str_subset(bfi.keys[[bfi_key_name]], \n    pattern = \"^-\"), pattern = \"^-\"))\n\n  raw_alpha std.alpha G6(smc) average_r S/N    ase mean  sd median_r\n      0.81      0.81     0.8      0.47 4.4 0.0056  3.2 1.2     0.41\n\n    95% confidence boundaries \n         lower alpha upper\nFeldt      0.8  0.81  0.82\nDuhachek   0.8  0.81  0.82\n\n Reliability if an item is dropped:\n   raw_alpha std.alpha G6(smc) average_r S/N alpha se  var.r med.r\nN1      0.76      0.76    0.71      0.44 3.1   0.0075 0.0061  0.41\nN2      0.76      0.76    0.72      0.45 3.2   0.0073 0.0054  0.41\nN3      0.76      0.76    0.73      0.44 3.1   0.0077 0.0178  0.39\nN4      0.80      0.80    0.77      0.49 3.9   0.0064 0.0181  0.49\nN5      0.81      0.81    0.79      0.52 4.3   0.0059 0.0137  0.53\n\n Item statistics \n      n raw.r std.r r.cor r.drop mean  sd\nN1 2778  0.80  0.80  0.76   0.67  2.9 1.6\nN2 2779  0.79  0.79  0.75   0.65  3.5 1.5\nN3 2789  0.81  0.81  0.74   0.67  3.2 1.6\nN4 2764  0.72  0.71  0.60   0.54  3.2 1.6\nN5 2771  0.68  0.67  0.53   0.49  3.0 1.6\n\nNon missing response frequency for each item\n      1    2    3    4    5    6 miss\nN1 0.24 0.24 0.15 0.19 0.12 0.07 0.01\nN2 0.12 0.19 0.15 0.26 0.18 0.10 0.01\nN3 0.18 0.23 0.13 0.21 0.16 0.09 0.00\nN4 0.17 0.24 0.15 0.22 0.14 0.09 0.01\nN5 0.24 0.24 0.14 0.18 0.12 0.09 0.01\n\n$openness\n\nReliability analysis   \nCall: psych::alpha(x = select(pivot_wider(x, names_from = items, values_from = value), \n    matches(\"\\\\w\\\\d\")), keys = str_remove(str_subset(bfi.keys[[bfi_key_name]], \n    pattern = \"^-\"), pattern = \"^-\"))\n\n  raw_alpha std.alpha G6(smc) average_r S/N   ase mean   sd median_r\n       0.6      0.61    0.57      0.24 1.5 0.012  4.6 0.81     0.23\n\n    95% confidence boundaries \n         lower alpha upper\nFeldt     0.58   0.6  0.62\nDuhachek  0.58   0.6  0.62\n\n Reliability if an item is dropped:\n    raw_alpha std.alpha G6(smc) average_r S/N alpha se  var.r med.r\nO1       0.53      0.53    0.48      0.22 1.1    0.014 0.0092  0.23\nO2-      0.57      0.57    0.51      0.25 1.3    0.013 0.0076  0.22\nO3       0.50      0.50    0.44      0.20 1.0    0.015 0.0071  0.20\nO4       0.61      0.62    0.56      0.29 1.6    0.012 0.0044  0.29\nO5-      0.51      0.53    0.47      0.22 1.1    0.015 0.0116  0.20\n\n Item statistics \n       n raw.r std.r r.cor r.drop mean  sd\nO1  2778  0.62  0.65  0.52   0.39  4.8 1.1\nO2- 2800  0.65  0.60  0.43   0.33  4.3 1.6\nO3  2772  0.67  0.69  0.59   0.45  4.4 1.2\nO4  2786  0.50  0.52  0.29   0.22  4.9 1.2\nO5- 2780  0.67  0.66  0.52   0.42  4.5 1.3\n\nNon missing response frequency for each item\n      1    2    3    4    5    6 miss\nO1 0.01 0.04 0.08 0.22 0.33 0.33 0.01\nO2 0.29 0.26 0.14 0.16 0.10 0.06 0.00\nO3 0.03 0.05 0.11 0.28 0.34 0.20 0.01\nO4 0.02 0.04 0.06 0.17 0.32 0.39 0.01\nO5 0.27 0.32 0.19 0.13 0.07 0.03 0.01\n```\n\n\n:::\n:::\n\n1. `pull`は最後に作られた列を返すので、実は`pull()`だけでもres_alpha列を引っ張ってこれます。\n\nということで、元のdfからmapを使って一気にα係数を求めることができました。一つのnamed listに下位尺度5つ分の出力が詰まっているので、オブジェクトに入れた際にGrobal Env.がオブジェクトだらけにならないというのはいい点かもしれないです。\n\n## やりやすくなさそうなデータの場合\n`bfi`データは列名に下位尺度の分類が含まれていたのでやりやすかったのですが、実際に扱うデータだとそうはいかない場合もあると思います。というわけで、`bfi`を少しいじってこんなデータを用意してみました。\n\n::: {.callout-note collapse=\"true\"}\n### 改造の処理はこちら\n`bfi`の列をデモグラフィック列（26-28）以外ランダムに並べ替えるために、列番号をシャッフルします。\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(20251025)\n\n(vec_col_order <- c(sample(1:25), 26:28))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] 23  7 13 25  1  3  5 10 17  8 21 22 15 16  4 19  6 18  9 20 12 11  2 14 24\n[26] 26 27 28\n```\n\n\n:::\n:::\n\n\n後でkeyを作る用のベクトルを作成。チェック用に元の`bfi`の列名を名前に付けておきます。\n\n::: {.cell}\n\n```{.r .cell-code}\nvec_names_df_test <- c(\n  paste0(\"q1_x\", 1:25),\n  paste0(\"q2_x\", 1:3)\n) |>\n  setNames(\n    colnames(bfi[, vec_col_order])\n  )\n\nvec_names_df_test\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       O3        C2        E3        O5        A1        A3        A5        C5 \n  \"q1_x1\"   \"q1_x2\"   \"q1_x3\"   \"q1_x4\"   \"q1_x5\"   \"q1_x6\"   \"q1_x7\"   \"q1_x8\" \n       N2        C3        O1        O2        E5        N1        A4        N4 \n  \"q1_x9\"  \"q1_x10\"  \"q1_x11\"  \"q1_x12\"  \"q1_x13\"  \"q1_x14\"  \"q1_x15\"  \"q1_x16\" \n       C1        N3        C4        N5        E2        E1        A2        E4 \n \"q1_x17\"  \"q1_x18\"  \"q1_x19\"  \"q1_x20\"  \"q1_x21\"  \"q1_x22\"  \"q1_x23\"  \"q1_x24\" \n       O4    gender education       age \n \"q1_x25\"   \"q2_x1\"   \"q2_x2\"   \"q2_x3\" \n```\n\n\n:::\n:::\n\n\n列番号をシャッフルしたベクトルを使って、列を並び替えたdfを作ります。ついでにid列もつけておきます。\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_test <- bfi[, vec_col_order] |>\n  `colnames<-`(vec_names_df_test) |>\n  rownames_to_column(var = \"id\")\n\ncolnames(df_test)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] \"id\"     \"q1_x1\"  \"q1_x2\"  \"q1_x3\"  \"q1_x4\"  \"q1_x5\"  \"q1_x6\"  \"q1_x7\" \n [9] \"q1_x8\"  \"q1_x9\"  \"q1_x10\" \"q1_x11\" \"q1_x12\" \"q1_x13\" \"q1_x14\" \"q1_x15\"\n[17] \"q1_x16\" \"q1_x17\" \"q1_x18\" \"q1_x19\" \"q1_x20\" \"q1_x21\" \"q1_x22\" \"q1_x23\"\n[25] \"q1_x24\" \"q1_x25\" \"q2_x1\"  \"q2_x2\"  \"q2_x3\" \n```\n\n\n:::\n:::\n\n\n構成要素の分類を示すkeyを作ります。実際の場合はnamed listを自力で作成すればいいと思います（それか、`psych::make.keys()`あたりを使うか）。今回は手入力したくないのでゴリ押します。\n\n::: {.cell}\n\n```{.r .cell-code}\nlist_test_keys <-\n  names(bfi.keys) |>\n  str_extract(pattern = \"^.\") |>\n  toupper() |>\n  set_names() |>\n  map(\n    .f = \\(x){\n      temp_vec <- vec_names_df_test[1:25]\n      temp_vec[str_starts(names(temp_vec), x)]\n    }\n  ) |>\n  map(\n    .f = \\(x) {\n      if_else(\n        names(x) %in% unlist(bfi.keys),\n        x,\n        paste0(\"-\", x) |>\n          set_names(names(x))\n      )\n    }\n  )\n\nlist_test_keys\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$A\n      A1       A3       A5       A4       A2 \n\"-q1_x5\"  \"q1_x6\"  \"q1_x7\" \"q1_x15\" \"q1_x23\" \n\n$C\n       C2        C5        C3        C1        C4 \n  \"q1_x2\"  \"-q1_x8\"  \"q1_x10\"  \"q1_x17\" \"-q1_x19\" \n\n$E\n       E3        E5        E2        E1        E4 \n  \"q1_x3\"  \"q1_x13\" \"-q1_x21\" \"-q1_x22\"  \"q1_x24\" \n\n$N\n      N2       N1       N4       N3       N5 \n \"q1_x9\" \"q1_x14\" \"q1_x16\" \"q1_x18\" \"q1_x20\" \n\n$O\n       O3        O5        O1        O2        O4 \n  \"q1_x1\"  \"-q1_x4\"  \"q1_x11\" \"-q1_x12\"  \"q1_x25\" \n```\n\n\n:::\n:::\n\n手入力の方がむしろ省コードだし楽だろ！！という指摘は今回はなかったことにします。\n\nちなみに逆転項目の設定はちゃんとできています。\n\n::: {.cell}\n\n```{.r .cell-code}\ndata.frame(\n  enframe(\n    unlist(list_test_keys)\n  ) |>\n    arrange(name),\n  enframe(\n    unlist(bfi.keys)\n  )\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   name   value         name.1 value.1\n1  A.A1  -q1_x5         agree1     -A1\n2  A.A2  q1_x23         agree2      A2\n3  A.A3   q1_x6         agree3      A3\n4  A.A4  q1_x15         agree4      A4\n5  A.A5   q1_x7         agree5      A5\n6  C.C1  q1_x17 conscientious1      C1\n7  C.C2   q1_x2 conscientious2      C2\n8  C.C3  q1_x10 conscientious3      C3\n9  C.C4 -q1_x19 conscientious4     -C4\n10 C.C5  -q1_x8 conscientious5     -C5\n11 E.E1 -q1_x22  extraversion1     -E1\n12 E.E2 -q1_x21  extraversion2     -E2\n13 E.E3   q1_x3  extraversion3      E3\n14 E.E4  q1_x24  extraversion4      E4\n15 E.E5  q1_x13  extraversion5      E5\n16 N.N1  q1_x14   neuroticism1      N1\n17 N.N2   q1_x9   neuroticism2      N2\n18 N.N3  q1_x18   neuroticism3      N3\n19 N.N4  q1_x16   neuroticism4      N4\n20 N.N5  q1_x20   neuroticism5      N5\n21 O.O1  q1_x11      openness1      O1\n22 O.O2 -q1_x12      openness2     -O2\n23 O.O3   q1_x1      openness3      O3\n24 O.O4  q1_x25      openness4      O4\n25 O.O5  -q1_x4      openness5     -O5\n```\n\n\n:::\n:::\n\n:::\n\n元のデータと行数列数は一緒ですが、列名と順番が変わりました。コードブックの作成が必須ですね。\n\n::: {.cell}\n\n```{.r .cell-code}\nstr(df_test)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n'data.frame':\t2800 obs. of  29 variables:\n $ id    : chr  \"61617\" \"61618\" \"61620\" \"61621\" ...\n $ q1_x1 : int  3 4 5 4 4 5 5 4 6 5 ...\n $ q1_x2 : int  3 4 5 4 4 6 4 2 6 5 ...\n $ q1_x3 : int  3 6 4 4 5 6 4 4 NA 4 ...\n $ q1_x4 : int  3 3 2 5 3 1 1 3 1 2 ...\n $ q1_x5 : int  2 2 5 4 2 6 2 4 4 2 ...\n $ q1_x6 : int  3 5 5 6 3 5 5 1 6 6 ...\n $ q1_x7 : int  4 5 4 5 5 5 5 1 3 5 ...\n $ q1_x8 : int  4 4 5 5 2 3 3 4 5 1 ...\n $ q1_x9 : int  4 3 5 5 3 5 2 3 5 5 ...\n $ q1_x10: int  3 4 4 3 5 6 4 4 3 6 ...\n $ q1_x11: int  3 4 4 3 3 4 5 3 6 5 ...\n $ q1_x12: int  6 2 2 3 3 3 2 2 6 1 ...\n $ q1_x13: int  4 3 5 4 5 6 5 1 3 5 ...\n $ q1_x14: int  3 3 4 2 2 3 1 6 5 5 ...\n $ q1_x15: int  4 2 4 5 4 6 3 5 3 6 ...\n $ q1_x16: int  2 5 2 4 4 2 1 6 3 2 ...\n $ q1_x17: int  2 5 4 4 4 6 5 3 6 6 ...\n $ q1_x18: int  2 3 4 2 4 2 2 2 2 5 ...\n $ q1_x19: int  4 3 2 5 3 1 2 2 4 2 ...\n $ q1_x20: int  3 5 3 1 3 3 1 4 3 4 ...\n $ q1_x21: int  3 1 4 3 2 1 3 6 3 2 ...\n $ q1_x22: int  3 1 2 5 2 2 4 3 5 2 ...\n $ q1_x23: int  4 4 4 4 3 6 5 3 3 5 ...\n $ q1_x24: int  4 4 4 4 4 5 5 2 4 5 ...\n $ q1_x25: int  4 3 5 3 3 6 6 5 6 5 ...\n $ q2_x1 : int  1 2 2 2 1 2 1 1 1 2 ...\n $ q2_x2 : int  NA NA NA NA NA 3 NA 2 1 NA ...\n $ q2_x3 : int  16 18 17 17 17 21 18 19 19 17 ...\n```\n\n\n:::\n:::\n\n\nそして構成要素の分類のkeyも用意しました。要素のベクトルに名前がついているのはチェックのためで、本来はないと思ってください。QualtricsとかMicrosoft Formsとかには項目をランダムに提示する機能があるので、それを使えば列をこんなにシャッフルする必要はないんですが、「よくわからなかったので、尺度の項目の順番を自分で頑張ってシャッフルしちゃいました…」という事案はあると思います。\n\n::: {.cell}\n\n```{.r .cell-code}\nlist_test_keys\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$A\n      A1       A3       A5       A4       A2 \n\"-q1_x5\"  \"q1_x6\"  \"q1_x7\" \"q1_x15\" \"q1_x23\" \n\n$C\n       C2        C5        C3        C1        C4 \n  \"q1_x2\"  \"-q1_x8\"  \"q1_x10\"  \"q1_x17\" \"-q1_x19\" \n\n$E\n       E3        E5        E2        E1        E4 \n  \"q1_x3\"  \"q1_x13\" \"-q1_x21\" \"-q1_x22\"  \"q1_x24\" \n\n$N\n      N2       N1       N4       N3       N5 \n \"q1_x9\" \"q1_x14\" \"q1_x16\" \"q1_x18\" \"q1_x20\" \n\n$O\n       O3        O5        O1        O2        O4 \n  \"q1_x1\"  \"-q1_x4\"  \"q1_x11\" \"-q1_x12\"  \"q1_x25\" \n```\n\n\n:::\n:::\n\n\nというわけで、こちらのデータでも`map()`で`alpha()`を一気に処理してみようと思います。先ほどはデータセットの列名に下位尺度の分類が入っていたので処理が少なく済みましたが、今回はそうではないので処理が少し増えます。\n\nまずlong型にした後、新たにマッチ用の列を作って逆転項目に-をつけます。（別にわざわざ新しい列を作らなくてもいいのですが、`alpha()`の出力のときに項目名の前後に-がつくのが気になるので、あえてマッチ用の列を作っています。）\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_test |>\n  pivot_longer(\n    cols = starts_with(\"q1\"),\n    names_to = \"items\"\n  ) |>\n  mutate(\n    match_items = if_else(\n      items %in% unlist(list_test_keys),\n      items,\n      str_c(\"-\", items)\n    )\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 70,000 × 7\n   id    q2_x1 q2_x2 q2_x3 items  value match_items\n   <chr> <int> <int> <int> <chr>  <int> <chr>      \n 1 61617     1    NA    16 q1_x1      3 q1_x1      \n 2 61617     1    NA    16 q1_x2      3 q1_x2      \n 3 61617     1    NA    16 q1_x3      3 q1_x3      \n 4 61617     1    NA    16 q1_x4      3 -q1_x4     \n 5 61617     1    NA    16 q1_x5      2 -q1_x5     \n 6 61617     1    NA    16 q1_x6      3 q1_x6      \n 7 61617     1    NA    16 q1_x7      4 q1_x7      \n 8 61617     1    NA    16 q1_x8      4 -q1_x8     \n 9 61617     1    NA    16 q1_x9      4 q1_x9      \n10 61617     1    NA    16 q1_x10     3 q1_x10     \n# ℹ 69,990 more rows\n```\n\n\n:::\n:::\n\n\n次に、マッチ用の列を`dplyr::case_match()`に入れて、分類用のリストと照合します。`case_match()`は、第一引数`.x`にマッチさせたいベクトル、以降はtwo-sided formula形式で処理を書いていきます。左側（LHS）はマッチさせたい要素、右側（RHS）にはマッチしたものに対する出力を入れます。このformulaの部分だけは頑張って書かないといけません。今回は分類リストがnamed listでその要素は文字列ベクトルなので、各要素にマッチしたらその要素のリスト名（＝下位尺度の分類）を返すようにします。\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_test |>\n  pivot_longer(\n    cols = starts_with(\"q1\"),\n    names_to = \"items\"\n  ) |>\n  mutate(\n    match_items = if_else(\n      items %in% unlist(list_test_keys),\n      items,\n      str_c(\"-\", items)\n    ),\n    nest_key = case_match(\n      match_items,\n      list_test_keys[[\"A\"]] ~ \"A\",\n      list_test_keys[[\"C\"]] ~ \"C\",\n      list_test_keys[[\"E\"]] ~ \"E\",\n      list_test_keys[[\"N\"]] ~ \"N\",\n      list_test_keys[[\"O\"]] ~ \"O\",\n    )\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 70,000 × 8\n   id    q2_x1 q2_x2 q2_x3 items  value match_items nest_key\n   <chr> <int> <int> <int> <chr>  <int> <chr>       <chr>   \n 1 61617     1    NA    16 q1_x1      3 q1_x1       O       \n 2 61617     1    NA    16 q1_x2      3 q1_x2       C       \n 3 61617     1    NA    16 q1_x3      3 q1_x3       E       \n 4 61617     1    NA    16 q1_x4      3 -q1_x4      O       \n 5 61617     1    NA    16 q1_x5      2 -q1_x5      A       \n 6 61617     1    NA    16 q1_x6      3 q1_x6       A       \n 7 61617     1    NA    16 q1_x7      4 q1_x7       A       \n 8 61617     1    NA    16 q1_x8      4 -q1_x8      C       \n 9 61617     1    NA    16 q1_x9      4 q1_x9       N       \n10 61617     1    NA    16 q1_x10     3 q1_x10      C       \n# ℹ 69,990 more rows\n```\n\n\n:::\n:::\n\n後の処理は先ほどと変わりません。nestしたうえでmap処理をしていけばいいです。\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_test |>\n  pivot_longer(\n    cols = starts_with(\"q1\"),\n    names_to = \"items\"\n  ) |>\n  mutate(\n    match_items = if_else(\n      items %in% unlist(list_test_keys),\n      items,\n      str_c(\"-\", items)\n    ),\n    nest_key = case_match(\n      match_items,\n      list_test_keys[[\"A\"]] ~ \"A\",\n      list_test_keys[[\"C\"]] ~ \"C\",\n      list_test_keys[[\"E\"]] ~ \"E\",\n      list_test_keys[[\"N\"]] ~ \"N\",\n      list_test_keys[[\"O\"]] ~ \"O\"\n    )\n  ) |>\n  nest(.by = nest_key) |>\n  arrange(nest_key) |> # <1>\n  mutate(\n    res_alpha = map(\n      .x = data,\n      .f = \\(x) {\n        x |>\n          select(-match_items) |> # <2>\n          pivot_wider(\n            names_from = items,\n            values_from = value\n          ) |>\n          select(starts_with(\"q1\")) |>\n          psych::alpha(\n            keys = list_test_keys[[nest_key]] |>\n              str_subset(\"^-\") |>\n              str_remove(\"^-\")\n          )\n      }\n    ) |>\n      set_names(nest_key),\n    .by = nest_key\n  ) |>\n  pull(res_alpha)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$A\n\nReliability analysis   \nCall: psych::alpha(x = select(pivot_wider(select(x, -match_items), \n    names_from = items, values_from = value), starts_with(\"q1\")), \n    keys = str_remove(str_subset(list_test_keys[[nest_key]], \n        \"^-\"), \"^-\"))\n\n  raw_alpha std.alpha G6(smc) average_r S/N   ase mean  sd median_r\n       0.7      0.71    0.68      0.33 2.5 0.009  4.7 0.9     0.34\n\n    95% confidence boundaries \n         lower alpha upper\nFeldt     0.69   0.7  0.72\nDuhachek  0.69   0.7  0.72\n\n Reliability if an item is dropped:\n       raw_alpha std.alpha G6(smc) average_r S/N alpha se  var.r med.r\nq1_x5-      0.72      0.72    0.67      0.40 2.6   0.0087 0.0065  0.38\nq1_x6       0.60      0.61    0.56      0.28 1.6   0.0124 0.0094  0.32\nq1_x7       0.64      0.66    0.60      0.32 1.9   0.0111 0.0125  0.34\nq1_x15      0.69      0.69    0.65      0.36 2.3   0.0098 0.0157  0.37\nq1_x23      0.62      0.63    0.58      0.29 1.7   0.0119 0.0168  0.29\n\n Item statistics \n          n raw.r std.r r.cor r.drop mean  sd\nq1_x5- 2784  0.58  0.57  0.38   0.31  4.6 1.4\nq1_x6  2774  0.76  0.77  0.71   0.59  4.6 1.3\nq1_x7  2784  0.69  0.70  0.59   0.49  4.6 1.3\nq1_x15 2781  0.65  0.63  0.47   0.39  4.7 1.5\nq1_x23 2773  0.73  0.75  0.67   0.56  4.8 1.2\n\nNon missing response frequency for each item\n          1    2    3    4    5    6 miss\nq1_x5  0.33 0.29 0.14 0.12 0.08 0.03 0.01\nq1_x6  0.03 0.06 0.07 0.20 0.36 0.27 0.01\nq1_x7  0.02 0.07 0.09 0.22 0.35 0.25 0.01\nq1_x15 0.05 0.08 0.07 0.16 0.24 0.41 0.01\nq1_x23 0.02 0.05 0.05 0.20 0.37 0.31 0.01\n\n$C\n\nReliability analysis   \nCall: psych::alpha(x = select(pivot_wider(select(x, -match_items), \n    names_from = items, values_from = value), starts_with(\"q1\")), \n    keys = str_remove(str_subset(list_test_keys[[nest_key]], \n        \"^-\"), \"^-\"))\n\n  raw_alpha std.alpha G6(smc) average_r S/N    ase mean   sd median_r\n      0.73      0.73    0.69      0.35 2.7 0.0081  4.3 0.95     0.34\n\n    95% confidence boundaries \n         lower alpha upper\nFeldt     0.71  0.73  0.74\nDuhachek  0.71  0.73  0.74\n\n Reliability if an item is dropped:\n        raw_alpha std.alpha G6(smc) average_r S/N alpha se  var.r med.r\nq1_x2        0.67      0.68    0.62      0.34 2.1   0.0099 0.0056  0.34\nq1_x8-       0.69      0.69    0.63      0.36 2.2   0.0096 0.0017  0.35\nq1_x10       0.69      0.69    0.64      0.36 2.3   0.0096 0.0070  0.36\nq1_x17       0.69      0.70    0.64      0.36 2.3   0.0093 0.0037  0.35\nq1_x19-      0.65      0.66    0.60      0.33 2.0   0.0107 0.0037  0.32\n\n Item statistics \n           n raw.r std.r r.cor r.drop mean  sd\nq1_x2   2776  0.70  0.71  0.60   0.50  4.4 1.3\nq1_x8-  2784  0.72  0.68  0.57   0.48  3.7 1.6\nq1_x10  2780  0.66  0.67  0.54   0.46  4.3 1.3\nq1_x17  2779  0.65  0.67  0.54   0.45  4.5 1.2\nq1_x19- 2774  0.74  0.73  0.64   0.55  4.4 1.4\n\nNon missing response frequency for each item\n          1    2    3    4    5    6 miss\nq1_x2  0.03 0.09 0.11 0.23 0.35 0.20 0.01\nq1_x8  0.18 0.20 0.12 0.22 0.17 0.10 0.01\nq1_x10 0.03 0.09 0.11 0.27 0.34 0.17 0.01\nq1_x17 0.03 0.06 0.10 0.24 0.37 0.21 0.01\nq1_x19 0.28 0.29 0.17 0.16 0.08 0.02 0.01\n\n$E\n\nReliability analysis   \nCall: psych::alpha(x = select(pivot_wider(select(x, -match_items), \n    names_from = items, values_from = value), starts_with(\"q1\")), \n    keys = str_remove(str_subset(list_test_keys[[nest_key]], \n        \"^-\"), \"^-\"))\n\n  raw_alpha std.alpha G6(smc) average_r S/N   ase mean  sd median_r\n      0.76      0.76    0.73      0.39 3.2 0.007  4.1 1.1     0.38\n\n    95% confidence boundaries \n         lower alpha upper\nFeldt     0.75  0.76  0.78\nDuhachek  0.75  0.76  0.78\n\n Reliability if an item is dropped:\n        raw_alpha std.alpha G6(smc) average_r S/N alpha se  var.r med.r\nq1_x3        0.73      0.73    0.67      0.40 2.7   0.0082 0.0071  0.40\nq1_x13       0.74      0.74    0.69      0.42 2.9   0.0078 0.0043  0.42\nq1_x21-      0.69      0.69    0.63      0.36 2.3   0.0095 0.0028  0.35\nq1_x22-      0.73      0.73    0.67      0.40 2.6   0.0084 0.0044  0.38\nq1_x24       0.70      0.70    0.65      0.37 2.4   0.0091 0.0033  0.38\n\n Item statistics \n           n raw.r std.r r.cor r.drop mean  sd\nq1_x3   2775  0.68  0.70  0.58   0.50  4.0 1.4\nq1_x13  2779  0.64  0.66  0.52   0.45  4.4 1.3\nq1_x21- 2784  0.78  0.76  0.69   0.61  3.9 1.6\nq1_x22- 2777  0.72  0.70  0.59   0.52  4.0 1.6\nq1_x24  2791  0.75  0.75  0.66   0.58  4.4 1.5\n\nNon missing response frequency for each item\n          1    2    3    4    5    6 miss\nq1_x3  0.05 0.11 0.15 0.30 0.27 0.13 0.01\nq1_x13 0.03 0.08 0.10 0.22 0.34 0.22 0.01\nq1_x21 0.19 0.24 0.12 0.22 0.14 0.09 0.01\nq1_x22 0.24 0.23 0.15 0.16 0.13 0.09 0.01\nq1_x24 0.05 0.09 0.10 0.16 0.34 0.26 0.00\n\n$N\n\nReliability analysis   \nCall: psych::alpha(x = select(pivot_wider(select(x, -match_items), \n    names_from = items, values_from = value), starts_with(\"q1\")), \n    keys = str_remove(str_subset(list_test_keys[[nest_key]], \n        \"^-\"), \"^-\"))\n\n  raw_alpha std.alpha G6(smc) average_r S/N    ase mean  sd median_r\n      0.81      0.81     0.8      0.47 4.4 0.0056  3.2 1.2     0.41\n\n    95% confidence boundaries \n         lower alpha upper\nFeldt      0.8  0.81  0.82\nDuhachek   0.8  0.81  0.82\n\n Reliability if an item is dropped:\n       raw_alpha std.alpha G6(smc) average_r S/N alpha se  var.r med.r\nq1_x9       0.76      0.76    0.72      0.45 3.2   0.0073 0.0054  0.41\nq1_x14      0.76      0.76    0.71      0.44 3.1   0.0075 0.0061  0.41\nq1_x16      0.80      0.80    0.77      0.49 3.9   0.0064 0.0181  0.49\nq1_x18      0.76      0.76    0.73      0.44 3.1   0.0077 0.0178  0.39\nq1_x20      0.81      0.81    0.79      0.52 4.3   0.0059 0.0137  0.53\n\n Item statistics \n          n raw.r std.r r.cor r.drop mean  sd\nq1_x9  2779  0.79  0.79  0.75   0.65  3.5 1.5\nq1_x14 2778  0.80  0.80  0.76   0.67  2.9 1.6\nq1_x16 2764  0.72  0.71  0.60   0.54  3.2 1.6\nq1_x18 2789  0.81  0.81  0.74   0.67  3.2 1.6\nq1_x20 2771  0.68  0.67  0.53   0.49  3.0 1.6\n\nNon missing response frequency for each item\n          1    2    3    4    5    6 miss\nq1_x9  0.12 0.19 0.15 0.26 0.18 0.10 0.01\nq1_x14 0.24 0.24 0.15 0.19 0.12 0.07 0.01\nq1_x16 0.17 0.24 0.15 0.22 0.14 0.09 0.01\nq1_x18 0.18 0.23 0.13 0.21 0.16 0.09 0.00\nq1_x20 0.24 0.24 0.14 0.18 0.12 0.09 0.01\n\n$O\n\nReliability analysis   \nCall: psych::alpha(x = select(pivot_wider(select(x, -match_items), \n    names_from = items, values_from = value), starts_with(\"q1\")), \n    keys = str_remove(str_subset(list_test_keys[[nest_key]], \n        \"^-\"), \"^-\"))\n\n  raw_alpha std.alpha G6(smc) average_r S/N   ase mean   sd median_r\n       0.6      0.61    0.57      0.24 1.5 0.012  4.6 0.81     0.23\n\n    95% confidence boundaries \n         lower alpha upper\nFeldt     0.58   0.6  0.62\nDuhachek  0.58   0.6  0.62\n\n Reliability if an item is dropped:\n        raw_alpha std.alpha G6(smc) average_r S/N alpha se  var.r med.r\nq1_x1        0.50      0.50    0.44      0.20 1.0    0.015 0.0071  0.20\nq1_x4-       0.51      0.53    0.47      0.22 1.1    0.015 0.0116  0.20\nq1_x11       0.53      0.53    0.48      0.22 1.1    0.014 0.0092  0.23\nq1_x12-      0.57      0.57    0.51      0.25 1.3    0.013 0.0076  0.22\nq1_x25       0.61      0.62    0.56      0.29 1.6    0.012 0.0044  0.29\n\n Item statistics \n           n raw.r std.r r.cor r.drop mean  sd\nq1_x1   2772  0.67  0.69  0.59   0.45  4.4 1.2\nq1_x4-  2780  0.67  0.66  0.52   0.42  4.5 1.3\nq1_x11  2778  0.62  0.65  0.52   0.39  4.8 1.1\nq1_x12- 2800  0.65  0.60  0.43   0.33  4.3 1.6\nq1_x25  2786  0.50  0.52  0.29   0.22  4.9 1.2\n\nNon missing response frequency for each item\n          1    2    3    4    5    6 miss\nq1_x1  0.03 0.05 0.11 0.28 0.34 0.20 0.01\nq1_x4  0.27 0.32 0.19 0.13 0.07 0.03 0.01\nq1_x11 0.01 0.04 0.08 0.22 0.33 0.33 0.01\nq1_x12 0.29 0.26 0.14 0.16 0.10 0.06 0.00\nq1_x25 0.02 0.04 0.06 0.17 0.32 0.39 0.01\n```\n\n\n:::\n:::\n\n1. dplyrとかで実装されている引数`.by`はデータを出現順に並べるので、データによっては出力がきれいな順番（A, B, C, ... ）にならないです。なので見やすくするために`dplyr::arrange()`でソートしておきます。\n2. マッチ用の列は残しておくとwide型にしたときにデータがズレるので外しておきます。マッチ用の列を作っていなかったら省略してOKです。\n\nこちらのデータでもうまくできました。\n\n# Conclusion\nというわけで、`purrr::map()`の中で`psych::alpha()`を使って、元のdfから一気にα係数の処理をしてみました。コードの可読性という観点からみると下位尺度ごとに処理をしてオブジェクトに入れていく方法の方が見てわかりやすいし、コードの量もそれほど多くならないので、map処理で一気にやる方法が実用的かはわかりません。ただ、パイプフローの中でシーケンシャルに進められる点やミスの原因となる要素の手入力を減らせる点が個人的にはいいと思います。",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}